{
  "model_name": "google/gemma-3-1b-it",
  "layer_idx": 13,
  "num_examples": 10,
  "max_new_tokens": 100,
  "activation_shape": [
    10,
    1152
  ],
  "num_correct": 2,
  "num_incorrect": 8,
  "accuracy": 0.2,
  "description": "MMLU activations collected on final non-EOS token after autoregressive generation. Labels are binary: 1=correct answer, 0=incorrect answer (including unparseable).",
  "files": {
    "activations": "cached_activations/mmlu_activations_layer_13_n10_activations.npy",
    "labels": "cached_activations/mmlu_activations_layer_13_n10_labels.npy",
    "subjects": "cached_activations/mmlu_activations_layer_13_n10_subjects.npy",
    "prompts": "cached_activations/mmlu_activations_layer_13_n10_prompts.npy",
    "questions": "cached_activations/mmlu_activations_layer_13_n10_questions.json",
    "generated_texts": "cached_activations/mmlu_activations_layer_13_n10_generated.npy",
    "predicted_answers": "cached_activations/mmlu_activations_layer_13_n10_predicted_answers.npy",
    "correct_answer_indices": "cached_activations/mmlu_activations_layer_13_n10_correct_answer_indices.npy"
  }
}